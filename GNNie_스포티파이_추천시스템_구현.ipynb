{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# data"
      ],
      "metadata": {
        "id": "-KEhH5hLateU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v_Zw4krnqAh",
        "outputId": "55ec737e-029c-43e1-ae7d-0800404d0fa0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data, Dataset\n",
        "\n",
        "class CustomData(Data):\n",
        "    \"\"\"\n",
        "    override __inc__ so DataLoader doesn't increment indices\n",
        "    \"\"\"\n",
        "    def __inc__(self, key, value, *args, **kwargs):\n",
        "        return 0\n",
        "\n",
        "class SpotData(Dataset):\n",
        "    \"\"\"\n",
        "    dataset with supervision/evaluation edges.\n",
        "    get(idx) return ALL outgoing edges of the graph of playlist \"idx\" since calculating metrics like recall@k needs all the playlist's positive edges\n",
        "    \"\"\"\n",
        "    def __init__(self, root, edge_index, transform=None, pre_transform=None):\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "        self.edge_index = edge_index\n",
        "        # playlists will all be in row 0, b/c sorted by RandLinkSplit\n",
        "        self.unique_idxs = torch.unique(edge_index[0,:]).tolist()\n",
        "        self.num_nodes = len(self.unique_idxs)\n",
        "\n",
        "    def len(self):\n",
        "        return self.num_nodes\n",
        "\n",
        "    # returns all outgoing edges associated with playlist idx\n",
        "    def get(self, idx):\n",
        "        edge_index = self.edge_index[:, self.edge_index[0,:] == idx]\n",
        "        return CustomData(edge_index=edge_index)\n"
      ],
      "metadata": {
        "id": "4YqtjCb2nW9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preprocessing"
      ],
      "metadata": {
        "id": "PAtCGor2vbmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1_vEYvwzsd9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install snap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf9AjEMGsgkK",
        "outputId": "1e93019d-59eb-4532-b5d2-52fe6e9bf71c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting snap\n",
            "  Downloading snap-0.5.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: snap\n",
            "  Building wheel for snap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for snap: filename=snap-0.5-py3-none-any.whl size=19393 sha256=75e2bc1d37cc9bd632c46377353f25d7798824476e1a4b5f35c0142f3cf27a36\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/bf/5e/6d570c7910ef2111228c9afe1f8590629917a951388898916e\n",
            "Successfully built snap\n",
            "Installing collected packages: snap\n",
            "Successfully installed snap-0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install snap-stanford\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXndPSgJW0RJ",
        "outputId": "7db02514-5132-4580-d8f3-a6c37087dd76"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement snap-stanford (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for snap-stanford\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "746COGgbwzYn",
        "outputId": "60be89a3-f455-4708-e3fa-f31933db9a87"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import json\n",
        "# import snap\n",
        "# import torch\n",
        "# from torch_geometric.data import Data\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# # argparse 대신 여기서 N과 K 값을 직접 정의\n",
        "# N = 100  # 예시: 데이터셋을 위해 사용할 파일의 수\n",
        "# K = 5    # 예시: K-core 그래프를 위한 값\n",
        "\n",
        "# def getFiles(N):\n",
        "#     '''\n",
        "#     returns:\n",
        "#         directory and files to use for dataset\n",
        "#     '''\n",
        "#     cwd = os.getcwd()\n",
        "#     dir = '/content/drive/My Drive/spotify_million_playlist_dataset/data'  # Google 드라이브 경로 지정\n",
        "#     files = os.listdir(dir)\n",
        "\n",
        "#     files = sorted(files, key=lambda x: int(x.split(\".\")[2].split(\"-\")[0]))\n",
        "#     return dir, files[:N]\n",
        "\n",
        "# def makeGraph(dir, files):\n",
        "#     '''\n",
        "#     returns:\n",
        "#         graph, number of original playlists and hashmap of PIDs/URIs\n",
        "#     '''\n",
        "#     # create undirected SNAP graph\n",
        "#     G = snap.TUNGraph.New()\n",
        "#     # create node for all playlist IDs\n",
        "#     for file in files:\n",
        "#         with open(os.path.join(dir, file), 'r') as f:\n",
        "#             data = json.load(f)['playlists']\n",
        "#             for playlist in data:\n",
        "#                 G.AddNode(playlist['pid'])\n",
        "\n",
        "#     # playlists indexed from [0, num_playlists - 1]\n",
        "#     # songs indexed from [num_playlists, num_playlist + num_songs]\n",
        "#     lastPID = max([n.GetId() for n in G.Nodes()])\n",
        "#     assert lastPID == len([n for n in G.Nodes()]) - 1\n",
        "#     SID = lastPID + 1\n",
        "#     # hashmap of { PID: {'name': _ } } and { URI : {'SID': _ , ... } }\n",
        "#     p_meta, uris = {}, {}\n",
        "\n",
        "#     for file in files:\n",
        "#         with open(os.path.join(dir, file), 'r') as f:\n",
        "#             data = json.load(f)['playlists']\n",
        "#             for playlist in data:\n",
        "#                 p_meta[playlist['pid']] = {'name': playlist['name']}\n",
        "#                 for song in playlist['tracks']:\n",
        "#                     uri = song['track_uri']\n",
        "#                     if uri not in uris:\n",
        "#                         uris[uri] = {\n",
        "#                             'SID': SID,\n",
        "#                             'track_name': song['track_name'],\n",
        "#                             'artist_name': song['artist_name'],\n",
        "#                             'artist_uri': song['artist_uri']\n",
        "#                         }\n",
        "#                         G.AddNode(SID)\n",
        "#                         SID += 1\n",
        "#                     # add edge between playlist and song\n",
        "#                     G.AddEdge(playlist['pid'], uris[uri]['SID'])\n",
        "#     orig_playlists = len([n for n in G.Nodes() if n.GetId() <= lastPID])\n",
        "#     return G, orig_playlists, lastPID, p_meta, uris\n",
        "\n",
        "# def getKCore(G, K, lastPID):\n",
        "#     '''\n",
        "#     returns:\n",
        "#         K-core graph, number of playlists, songs and edges\n",
        "#     '''\n",
        "#     G = G.GetKCore(K)\n",
        "#     if G.Empty():\n",
        "#         raise Exception(f\"No graph exists for K={K}\")\n",
        "#     num_playlists = len([n for n in G.Nodes() if n.GetId() <= lastPID])\n",
        "#     num_songs = len([n for n in G.Nodes() if n.GetId() > lastPID])\n",
        "#     num_edges = len([x for x in G.Edges()])\n",
        "#     return G, num_playlists, num_songs, num_edges\n",
        "\n",
        "# def reindexGraph(G, orig_playlists, num_playlists, num_songs, p_meta, uris):\n",
        "#     # create hashmap converting old IDs to new IDs\n",
        "#     ID, PIDs, SIDs = 0, {}, {}\n",
        "#     for N in G.Nodes():\n",
        "#         oldID = N.GetId()\n",
        "#         assert oldID not in PIDs and oldID not in SIDs\n",
        "#         if oldID <= orig_playlists - 1:\n",
        "#             PIDs[oldID] = ID\n",
        "#         else:\n",
        "#             SIDs[oldID] = ID\n",
        "#         ID += 1\n",
        "#     assert max(PIDs.values()) == num_playlists - 1\n",
        "#     assert len(PIDs.values()) == num_playlists\n",
        "#     assert max(SIDs.values()) == len([n for n in G.Nodes()]) - 1\n",
        "#     assert len(SIDs.values()) == num_songs\n",
        "\n",
        "#     # hashmap of { SID : {'track_uri': _ , ... } }\n",
        "#     s_meta = {}\n",
        "#     for uri, info in uris.items():\n",
        "#         if info['SID'] in SIDs:\n",
        "#             newID = SIDs[info['SID']]\n",
        "#             s_meta[newID] = {\n",
        "#                 'track_uri': uri,\n",
        "#                 'track_name': info['track_name'],\n",
        "#                 'artist_name': info['artist_name'],\n",
        "#                 'artist_uri': info['artist_uri']\n",
        "#             }\n",
        "#     p_meta = { PIDs[k]: v for k, v in p_meta.items() if k in PIDs }\n",
        "#     return G, p_meta, s_meta, PIDs, SIDs\n",
        "\n",
        "# def createPyObject(G, PIDs, SIDs):\n",
        "#     # convert to edge_index and storing in a PyG Data object\n",
        "#     edges = []\n",
        "#     for E in tqdm(G.Edges()):\n",
        "#         # create all edges from playlist -> song\n",
        "#         assert (E.GetSrcNId() in PIDs) and (E.GetSrcNId() not in SIDs)\n",
        "#         assert (E.GetDstNId() in SIDs) and (E.GetDstNId() not in PIDs)\n",
        "#         edge = [PIDs[E.GetSrcNId()], SIDs[E.GetDstNId()]]\n",
        "#         edges.append(edge)\n",
        "#         edges.append(edge[::-1])\n",
        "#     edge_idx = torch.LongTensor(edges)\n",
        "#     return Data(edge_index=edge_idx.t().contiguous(), num_nodes=G.GetNodes())\n",
        "\n",
        "# def saveObject(data, p_meta, s_meta, num_playlists, num_songs, num_edges, K, N):\n",
        "\n",
        "#     cwd = os.getcwd()\n",
        "#     dir = os.path.join(cwd, 'data')\n",
        "#     if not os.path.exists(dir):\n",
        "#         os.makedirs(dir)\n",
        "#     torch.save(data, os.path.join(dir, 'data_object.pt'))\n",
        "#     dataset = {'num_playlists': num_playlists, 'num_nodes': num_playlists + num_songs, 'kcore_value_k': K, 'num_spotify_files_used': N, 'num_edges_directed': 2 * num_edges, 'num_edges_undirected': num_edges}\n",
        "#     with open(os.path.join(dir, 'graph_info.json'), 'w') as f:\n",
        "#         json.dump(dataset, f)\n",
        "#     with open(os.path.join(dir, 'playlist_info.json'), 'w') as f:\n",
        "#         json.dump(p_meta, f)\n",
        "#     with open(os.path.join(dir, 'song_info.json'), 'w') as f:\n",
        "#         json.dump(s_meta, f)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     # N, K = parseArgs() 대신에 직접 정의된 N, K를 사용\n",
        "#     dir, files = getFiles(N)\n",
        "#     G, orig_playlists, lastPID, p_meta, uris = makeGraph(dir, files)\n",
        "#     G, num_playlists, num_songs, num_edges = getKCore(G, K, lastPID)\n",
        "#     G, p_meta, s_meta, PIDs, SIDs = reindexGraph(G, orig_playlists, num_playlists, num_songs, p_meta, uris)\n",
        "#     data = createPyObject(G, PIDs, SIDs)\n",
        "#     saveObject(data, p_meta, s_meta, num_playlists, num_songs, num_edges, K, N)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "hPzUJoR9sXVX",
        "outputId": "7f90265f-2b2a-4dfe-ab5c-35d5edd69436"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'snap' has no attribute 'TUNGraph'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-fa52994f0e9e>\u001b[0m in \u001b[0;36m<cell line: 138>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;31m# N, K = parseArgs() 대신에 직접 정의된 N, K를 사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetFiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_playlists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlastPID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakeGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_playlists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_songs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetKCore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlastPID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIDs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreindexGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_playlists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_playlists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_songs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muris\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-fa52994f0e9e>\u001b[0m in \u001b[0;36mmakeGraph\u001b[0;34m(dir, files)\u001b[0m\n\u001b[1;32m     28\u001b[0m     '''\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# create undirected SNAP graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msnap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTUNGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;31m# create node for all playlist IDs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'snap' has no attribute 'TUNGraph'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install networkx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZJLDcNXW-rw",
        "outputId": "cb620736-3d8d-4465-c307-0527fc312858"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "\n",
        "import os\n",
        "import json\n",
        "import networkx as nx\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Example values for N and K\n",
        "N = 100  # Number of files to use for the dataset\n",
        "K = 5    # Value for K-core decomposition\n",
        "\n",
        "def getFiles(N):\n",
        "    '''\n",
        "    Returns directory and files to use for dataset\n",
        "    '''\n",
        "    dir = '/content/drive/My Drive/spotify_million_playlist_dataset/data'\n",
        "    files = sorted(os.listdir(dir), key=lambda x: int(x.split(\".\")[2].split(\"-\")[0]))\n",
        "    return dir, files[:N]\n",
        "\n",
        "def makeGraph(dir, files):\n",
        "    '''\n",
        "    Returns a graph, number of original playlists, and hashmap of PIDs/URIs\n",
        "    '''\n",
        "    G = nx.Graph()\n",
        "    p_meta, uris = {}, {}\n",
        "    SID = 0\n",
        "\n",
        "    for file in files:\n",
        "        with open(os.path.join(dir, file), 'r') as f:\n",
        "            data = json.load(f)['playlists']\n",
        "            for playlist in data:\n",
        "                pid = playlist['pid']\n",
        "                G.add_node(pid, type='playlist')\n",
        "                p_meta[pid] = {'name': playlist['name']}\n",
        "                for song in playlist['tracks']:\n",
        "                    uri = song['track_uri']\n",
        "                    if uri not in uris:\n",
        "                        uris[uri] = {'SID': SID, 'track_name': song['track_name'],\n",
        "                                     'artist_name': song['artist_name'], 'artist_uri': song['artist_uri']}\n",
        "                        G.add_node(SID, type='song')\n",
        "                        SID += 1\n",
        "                    G.add_edge(pid, uris[uri]['SID'])\n",
        "\n",
        "    orig_playlists = sum(1 for _, data in G.nodes(data=True) if data['type'] == 'playlist')\n",
        "    return G, orig_playlists, SID - 1, p_meta, uris\n",
        "\n",
        "def getKCore(G, K):\n",
        "    '''\n",
        "    Returns K-core graph, number of playlists, songs, and edges\n",
        "    '''\n",
        "    G_kcore = nx.k_core(G, k=K)\n",
        "    num_playlists = sum(1 for _, data in G_kcore.nodes(data=True) if data['type'] == 'playlist')\n",
        "    num_songs = sum(1 for _, data in G_kcore.nodes(data=True) if data['type'] == 'song')\n",
        "    num_edges = G_kcore.number_of_edges()\n",
        "    return G_kcore, num_playlists, num_songs, num_edges\n",
        "\n",
        "def reindexGraph(G, orig_playlists, num_playlists, num_songs, p_meta, uris):\n",
        "    # NetworkX handles node indexing internally, so this step might be simplified\n",
        "    # depending on the specific needs of reindexing in your application\n",
        "    # This step is highly specific to the original snap application and may not be directly applicable in NetworkX\n",
        "    pass\n",
        "\n",
        "def createPyObject(G):\n",
        "    # Convert to edge_index and storing in a PyG Data object\n",
        "    edge_list = [(u, v) for u, v in G.edges()]\n",
        "    edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
        "    return Data(edge_index=edge_index, num_nodes=G.number_of_nodes())\n",
        "\n",
        "def saveObject(data, p_meta, s_meta, num_playlists, num_songs, num_edges, K, N):\n",
        "    # Save the data object and metadata as before\n",
        "    # Implementation remains the same as in your original code\n",
        "    pass\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    dir, files = getFiles(N)\n",
        "    G, orig_playlists, lastPID, p_meta, uris = makeGraph(dir, files)\n",
        "    G_kcore, num_playlists, num_songs, num_edges = getKCore(G, K)\n",
        "    # Reindexing might not be necessary or needs adaptation\n",
        "    data = createPyObject(G_kcore)\n",
        "    saveObject(data, p_meta, s_meta, num_playlists, num_songs, num_edges, K, N)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "uRGgoGINXRQs",
        "outputId": "687ab0a1-d448-4040-d628-c160b120cd38"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[Errno 107] Transport endpoint is not connected",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-54721ff234c3>\u001b[0m in \u001b[0;36mmakeGraph\u001b[0;34m(dir, files)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'playlists'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mplaylist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-54721ff234c3>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetFiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_playlists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlastPID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakeGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mG_kcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_playlists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_songs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetKCore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# Reindexing might not be necessary or needs adaptation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-54721ff234c3>\u001b[0m in \u001b[0;36mmakeGraph\u001b[0;34m(dir, files)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'playlists'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mplaylist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN"
      ],
      "metadata": {
        "id": "XPRFeRdIXnxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR') # only show error messages\n",
        "\n",
        "from recommenders.utils.timer import Timer\n",
        "from recommenders.models.deeprec.models.graphrec.lightgcn import LightGCN"
      ],
      "metadata": {
        "id": "DvIs-MqjoTCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install recommender-system"
      ],
      "metadata": {
        "id": "JjwKSdvHn6SI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py\n",
        "!pip install typing-extensions\n",
        "!pip install wheel"
      ],
      "metadata": {
        "id": "WdWGzXX9qmVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e git+https://github.com/microsoft/recommenders/#egg=recommenders"
      ],
      "metadata": {
        "id": "WPaMBV91pz7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install recommenders"
      ],
      "metadata": {
        "id": "C_nElz9PrLTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import recommenders\n",
        "from recommenders.models.deeprec.models.graphrec.lightgcn import LightGCN"
      ],
      "metadata": {
        "id": "GOgj1RZAoS4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gnn"
      ],
      "metadata": {
        "id": "V-T4YpkhsFp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from lightGCN import LightGCN\n",
        "from utils import recall\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    \"\"\"\n",
        "    full GNN with learnable playlist/song embeddings and LightGCN layers\n",
        "    \"\"\"\n",
        "    def __init__(self, emb_dim, num_nodes, num_playlists, num_layers):\n",
        "        super(GNN, self).__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_nodes = num_nodes\n",
        "        self.num_playlists = num_playlists\n",
        "        self.num_layers = num_layers\n",
        "        self.embeddings = torch.nn.Embedding(\n",
        "          num_embeddings=self.num_nodes,\n",
        "          embedding_dim=self.emb_dim\n",
        "        )\n",
        "        nn.init.normal_(self.embeddings.weight, std=0.1)\n",
        "        self.layers = nn.ModuleList()\n",
        "        for _ in range(self.num_layers):\n",
        "            self.layers.append(LightGCN())\n",
        "        self.sigmoid = torch.sigmoid\n",
        "\n",
        "    def forward(self):\n",
        "        raise NotImplementedError(\"Do not use.\")\n",
        "\n",
        "    def gnn_propagation(self, edge_index_mp):\n",
        "        \"\"\"\n",
        "        func:\n",
        "          performn linear embedding propagation via lightGCN layers\n",
        "        args:\n",
        "          edge_index_mp: a tensor of all message passing edges\n",
        "        returns:\n",
        "          final multi-scale embeddings for all playlist/songs\n",
        "        \"\"\"\n",
        "        l = self.embeddings.weight # layer-0 embeddings\n",
        "        layers = [l]\n",
        "        # GNN propagation loop\n",
        "        for i in range(self.num_layers):\n",
        "            l = self.layers[i](l, edge_index_mp)\n",
        "            layers.append(l)\n",
        "        return torch.stack(layers, dim=0).mean(dim=0)\n",
        "\n",
        "    def predict_scores(self, edge_index, embs):\n",
        "        \"\"\"\n",
        "        func:\n",
        "          computes predicted scores for each playlist/song pair via dot product\n",
        "        args:\n",
        "          edge_index: tensor of playlist/song edges we compute\n",
        "          embs: node embeddings for calculating predicted scores (typically the multi-scale embeddings from gnn_propagation())\n",
        "        returns:\n",
        "          predicted scores for each playlist/song pair in edge_index\n",
        "        \"\"\"\n",
        "        # dot product for each playlist/song pair\n",
        "        scores = embs[edge_index[0,:], :] * embs[edge_index[1,:], :]\n",
        "        return self.sigmoid(scores.sum(dim=1))\n",
        "\n",
        "    def loss(self, data_mp, data_pos, data_neg):\n",
        "        \"\"\"\n",
        "        func:\n",
        "          training set. GNN propagation on message passing edges. predict scores on training examples. calculate Bayesian Personalized Ranking.\n",
        "        args:\n",
        "          data_mp: tensor of message passing edges\n",
        "          data_pos: set of positive edges for loss calculation\n",
        "          data_neg: set of negative edges for loss calculation\n",
        "        returns:\n",
        "          loss calculated on the positive/negative training edges\n",
        "        \"\"\"\n",
        "        final_embs = self.gnn_propagation(data_mp.edge_index)\n",
        "        # get edge prediction scores for all positive/negative evaluation edges\n",
        "        pos_scores = self.predict_scores(data_pos.edge_index, final_embs)\n",
        "        neg_scores = self.predict_scores(data_neg.edge_index, final_embs)\n",
        "        loss = -torch.log(self.sigmoid(pos_scores - neg_scores)).mean()\n",
        "        return loss\n",
        "\n",
        "    def evaluation(self, data_mp, data_pos, k):\n",
        "        \"\"\"\n",
        "        func:\n",
        "          calculate recall@k on validation/test set\n",
        "        args:\n",
        "          data_mp: tensor of message passing edges\n",
        "          data_pos: set of positive edges for scoring metric\n",
        "          k: k for recall@k\n",
        "        returns:\n",
        "          hashmap of { PID: recall@k }\n",
        "        \"\"\"\n",
        "        final_embs = self.gnn_propagation(data_mp.edge_index)\n",
        "        # embeddings of all unique playlists in the batch of evaluation edges\n",
        "        unique_playlists = torch.unique_consecutive(data_pos.edge_index[0,:])\n",
        "        # shape [ playlists_in_batch, EMB_DIM ]\n",
        "        playlist_emb = final_embs[unique_playlists, :]\n",
        "        # shape [ songs_in_dataset, EMB_DIM ]\n",
        "        song_emb = final_embs[self.num_playlists:, :]\n",
        "        # entry i,j is rating of song j for playlist i\n",
        "        ratings = self.sigmoid(torch.matmul(playlist_emb, song_emb.t()))\n",
        "        result = recall(ratings.cpu(), k, self.num_playlists, data_pos.edge_index.cpu(), unique_playlists.cpu(), data_mp.edge_index.cpu())\n",
        "        return result\n"
      ],
      "metadata": {
        "id": "qv918JOtaY7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lightGCN"
      ],
      "metadata": {
        "id": "wf6OucPyWLhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import degree\n",
        "\n",
        "class LightGCN(MessagePassing):\n",
        "  \"\"\"\n",
        "  a single LightGCN layer\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(LightGCN, self).__init__(aggr='add')\n",
        "\n",
        "  def message(self, x_j, norm):\n",
        "    '''\n",
        "    args:\n",
        "      x_j: node embeddings of neighbors of shape [E, emb_dim]\n",
        "      norm: normalization calculated in forward()\n",
        "    returns:\n",
        "      message from neighboring nodes j to central node i\n",
        "    '''\n",
        "    return norm.view(-1, 1) * x_j\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    \"\"\"\n",
        "    args:\n",
        "      x: current node embeddings of shape [N, emb_dim]\n",
        "      edge_index: message passing edges of shape [2, E]\n",
        "    returns:\n",
        "      updated embeddings after this layer\n",
        "    \"\"\"\n",
        "    row, col = edge_index\n",
        "    deg = degree(col)\n",
        "    deg_inv_sqrt = deg.pow(-0.5)\n",
        "    norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "    return self.propagate(edge_index, x=x, norm=norm)"
      ],
      "metadata": {
        "id": "I2_nUBkMV-b0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# util.py"
      ],
      "metadata": {
        "id": "qQeYEeuLWHgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "def sampleNeg(batch, num_playlists, num_nodes):\n",
        "   negs = []\n",
        "   for _ in batch.edge_index[0,:]:\n",
        "      rand = torch.randint(num_playlists, num_nodes, (1,))\n",
        "      negs.append(rand.item())\n",
        "   edge_index_negs = torch.row_stack([\n",
        "      batch.edge_index[0,:], torch.LongTensor(negs)\n",
        "   ])\n",
        "   return Data(edge_index=edge_index_negs)\n",
        "\n",
        "def recall(all_ratings, k, num_playlists, ground_truth, unique_playlists, data_mp):\n",
        "   \"\"\"\n",
        "   Calculates recall@k during validation/testing for a single batch.\n",
        "\n",
        "   args:\n",
        "     all_ratings: array of shape [number of playlists in batch, number of songs in whole dataset]\n",
        "     k: the value of k to use for recall@k\n",
        "     num_playlists: the number of playlists in the dataset\n",
        "     ground_truth: array of shape [2, X] where each column is a pair of (playlist_idx, positive song idx). This is the\n",
        "        batch that we are calculating metrics on.\n",
        "     unique_playlists: 1D vector of length [number of playlists in batch], which specifies which playlist corresponds\n",
        "        to each row of all_ratings\n",
        "     data_mp: an array of shape [2, Y]. This is all of the known message-passing edges. We will use this to make sure we\n",
        "        don't recommend songs that are already known to be in the playlist.\n",
        "   returns:\n",
        "     Dictionary of playlist ID -> recall@k on that playlist\n",
        "   \"\"\"\n",
        "   # We don't want to recommend songs that are already known to be in the playlist.\n",
        "   # Set those to a low rating so they won't be recommended\n",
        "   known_edges = data_mp[:, data_mp[0,:] < num_playlists] # removing duplicate edges (since data_mp is undirected). also makes it so that for each column, playlist idx is in row 0 and song idx is in row 1\n",
        "   playlist_to_idx_in_batch = {playlist: i for i, playlist in enumerate(unique_playlists.tolist())}\n",
        "   exclude_playlists, exclude_songs = [], [] # already-known playlist/song links. Don't want to recommend these again\n",
        "   for i in range(known_edges.shape[1]): # looping over all known edges\n",
        "      pl, song = known_edges[:,i].tolist()\n",
        "      if pl in playlist_to_idx_in_batch: # don't need the edges in data_mp that are from playlists that are not in this batch\n",
        "         exclude_playlists.append(playlist_to_idx_in_batch[pl])\n",
        "         exclude_songs.append(song - num_playlists) # subtract num_playlists to get indexing into all_ratings correct\n",
        "   all_ratings[exclude_playlists, exclude_songs] = -10000 # setting to a very low score so they won't be recommended\n",
        "\n",
        "   # Get top k recommendations for each playlist\n",
        "   _, top_k = torch.topk(all_ratings, k=k, dim=1)\n",
        "   top_k += num_playlists # topk returned indices of songs in ratings, which doesn't include playlists. Need to shift up by num_playlists to get the actual song indices\n",
        "\n",
        "   ret = {}\n",
        "   for i, playlist in enumerate(unique_playlists):\n",
        "      pos_songs = ground_truth[1, ground_truth[0, :] == playlist]\n",
        "      k_recs = top_k[i, :] # top k recommendations for playlist\n",
        "      recall = len(np.intersect1d(pos_songs, k_recs)) / len(pos_songs)\n",
        "      ret[playlist] = recall\n",
        "   return ret"
      ],
      "metadata": {
        "id": "-pPM6jZfWB98"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main"
      ],
      "metadata": {
        "id": "rttlKPnAa6R8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "from GNN import GNN\n",
        "from torch_geometric import seed_everything\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "from torch_geometric.data import Data\n",
        "from utils import sampleNeg\n",
        "from data import SpotData\n",
        "\n",
        "def train(model, data_mp, loader, opt, num_playlists, num_nodes, device):\n",
        "    \"\"\"\n",
        "    args:\n",
        "       model: GNN model\n",
        "       data_mp: message passing edges\n",
        "       loader: dataloader for eval edges\n",
        "       opt: the optimizer\n",
        "       num_playlists: number of total playlists\n",
        "       num_nodes: number of total nodes\n",
        "       device: CPU/GPU\n",
        "    returns:\n",
        "       epoch's training loss\n",
        "    \"\"\"\n",
        "    loss, samples = 0, 0\n",
        "    model.train() # set module in training mode\n",
        "    for batch in loader:\n",
        "        data_mp, batch = data_mp.to(device), batch.to(device)\n",
        "        negs = sampleNeg(batch, num_playlists, num_nodes).to(device)\n",
        "        # forward + backprop + loss + update\n",
        "        loss = model.loss(data_mp, batch, negs)\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        # compute metrics\n",
        "        sample = batch.edge_index.shape[1]\n",
        "        loss += loss.item() * sample\n",
        "        samples += sample\n",
        "    return loss / samples\n",
        "\n",
        "def test(model, data_mp, loader, k, device, save_dir, epoch):\n",
        "    \"\"\"\n",
        "    args:\n",
        "       model: GNN model\n",
        "       data_mp: message passing edges\n",
        "       loader: dataloader for eval edges\n",
        "       k: k for recall@k\n",
        "       device: CPU/GPU\n",
        "       save_dir: dir to save embeddings\n",
        "       epoch: number of the current epoch\n",
        "    returns:\n",
        "       recall@k for this epoch\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    recalls = {}\n",
        "    with torch.no_grad():\n",
        "        data_mp = data_mp.to(device)\n",
        "        if save_dir is not None:\n",
        "            embs = gnn.gnn_propagation(data_mp.edge_index)\n",
        "            torch.save(embs, os.path.join(save_dir, f\"epoch_{epoch}.pt\"))\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            recalls.update(model.evaluation(data_mp, batch, k))\n",
        "    return np.mean(list(recalls.values()))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    seed_everything(5)\n",
        "    epochs = 30\n",
        "    k = 300\n",
        "    num_layers = 3 # number of LightGCN layers (number of hops)\n",
        "    batch_size = 2048  # number of playlists in the batch\n",
        "    emb_dim = 64 # dimension for the playlist/song embeddings\n",
        "    emb_dir = 'embeddings'  # path to save embeddings\n",
        "    if not os.path.exists(emb_dir):\n",
        "        os.makedirs(emb_dir)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    data = torch.load(\"data/data_object.pt\")\n",
        "    with open(\"data/graph_info.json\", 'r') as f:\n",
        "        info = json.load(f)\n",
        "    num_playlists, num_nodes = info[\"num_playlists\"], info[\"num_nodes\"]\n",
        "\n",
        "    # train/val/test split (70-15-15)\n",
        "    transform = RandomLinkSplit(\n",
        "        is_undirected=True,\n",
        "        add_negative_train_samples=False,\n",
        "        neg_sampling_ratio=0, num_val=0.15,\n",
        "        num_test=0.15\n",
        "    )\n",
        "    train_split, val_split, test_split = transform(data)\n",
        "\n",
        "    # create message passing edges for propagation AND evaluation edges\n",
        "    train_mp = Data(edge_index=train_split.edge_index)\n",
        "    val_mp = Data(edge_index=val_split.edge_index)\n",
        "    test_mp = Data(edge_index=test_split.edge_index)\n",
        "    train_ev = SpotData('temp', edge_index=train_split.edge_label_index)\n",
        "    val_ev = SpotData('temp', edge_index=val_split.edge_label_index)\n",
        "    test_ev = SpotData('temp', edge_index=test_split.edge_label_index)\n",
        "\n",
        "    # dataLoaders for the supervision/evaluation edges\n",
        "    train_loader = DataLoader(train_ev, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_ev, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_ev, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # initialize GNN model\n",
        "    gnn = GNN(\n",
        "        emb_dim=emb_dim,\n",
        "        num_nodes=data.num_nodes,\n",
        "        num_playlists=num_playlists,\n",
        "        num_layers=num_layers\n",
        "    ).to(device)\n",
        "    opt = torch.optim.Adam(gnn.parameters(), lr=1e-3)\n",
        "\n",
        "    # list of [epoch, train loss / val recall@K ]\n",
        "    losses, vals = [], []\n",
        "    for e in range(epochs):\n",
        "        loss = train(\n",
        "            gnn, train_mp, train_loader, opt,\n",
        "            num_playlists,  num_nodes, device\n",
        "        )\n",
        "        losses.append((e, loss))\n",
        "        if e % 5 == 0:\n",
        "            val = test(gnn, val_mp, val_loader, k, device, emb_dir, e)\n",
        "            vals.append((e, val))\n",
        "            print(f\"Epoch {e}: train_loss={loss}, val_recall={val}\")\n",
        "        else:\n",
        "            print(f\"Epoch {e}: train_loss={loss}\")\n",
        "\n",
        "    best_val = max(vals, key = lambda x: x[1])\n",
        "    print(f\"Best val recall@k: {best_val[1]} @ epoch {best_val[0]}\")\n",
        "\n",
        "    test_recall = test(gnn, test_mp, test_loader, k, device, None, None)\n",
        "    print(f\"Test recall@k: {test_recall}\")\n"
      ],
      "metadata": {
        "id": "KvbD0VeOa-ET"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}